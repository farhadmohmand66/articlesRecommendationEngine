{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Research Papers Recomendation System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tried to make a content-based recommendation system for research articles using NearestNeighbors unsupervised learning methods.NearestNeighbors is an unsupervised technique of finding the nearest data points with respect to each data point. Visit the following link for additional information about the Nearest Neighbors unsupervised learning-based method: https://scikit-learn.org/stable/modules/neighbors.html\n",
    "The data is downloaded from the IEEE website, and all these research publications are  Conferences and journal papers of the year 2022 and early access of 2023. All research articles belong to the area of AI, Data Science, Machine learning, Deep Learning, Data Mining, and NLP.  Total records are 1559.\n",
    "data source website : https://ieeexplore.ieee.org/Xplore/home.jsp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = pd.read_csv('ieeeArticles2022_2023.csv') # import the file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sno</th>\n",
       "      <th>Document Title</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Author Affiliations</th>\n",
       "      <th>Publication Title</th>\n",
       "      <th>Date Added To Xplore</th>\n",
       "      <th>Publication Year</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Issue</th>\n",
       "      <th>Start Page</th>\n",
       "      <th>...</th>\n",
       "      <th>Mesh_Terms</th>\n",
       "      <th>Article Citation Count</th>\n",
       "      <th>Patent Citation Count</th>\n",
       "      <th>Reference Count</th>\n",
       "      <th>License</th>\n",
       "      <th>Online Date</th>\n",
       "      <th>Issue Date</th>\n",
       "      <th>Meeting Date</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Document Identifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>KTI-RNN: Recognition of Heart Failure from Cli...</td>\n",
       "      <td>D. Li; H. Ma; W. Li; B. Zhao; J. Zhao; Y. Liu;...</td>\n",
       "      <td>College of Data Science, Taiyuan University of...</td>\n",
       "      <td>Tsinghua Science and Technology</td>\n",
       "      <td>21-Jul-22</td>\n",
       "      <td>2023</td>\n",
       "      <td>28</td>\n",
       "      <td>1.0</td>\n",
       "      <td>117</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21-Jul-22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TUP</td>\n",
       "      <td>TUP Journals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Blockchain Data Analysis from the Perspective ...</td>\n",
       "      <td>W. Song; W. Zhang; J. Wang; L. Zhai; P. Jiang;...</td>\n",
       "      <td>School of Information Science and Engineering,...</td>\n",
       "      <td>Tsinghua Science and Technology</td>\n",
       "      <td>21-Jul-22</td>\n",
       "      <td>2023</td>\n",
       "      <td>28</td>\n",
       "      <td>1.0</td>\n",
       "      <td>176</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21-Jul-22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TUP</td>\n",
       "      <td>TUP Journals</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sno                                     Document Title  \\\n",
       "0    1  KTI-RNN: Recognition of Heart Failure from Cli...   \n",
       "1    2  Blockchain Data Analysis from the Perspective ...   \n",
       "\n",
       "                                             Authors  \\\n",
       "0  D. Li; H. Ma; W. Li; B. Zhao; J. Zhao; Y. Liu;...   \n",
       "1  W. Song; W. Zhang; J. Wang; L. Zhai; P. Jiang;...   \n",
       "\n",
       "                                 Author Affiliations  \\\n",
       "0  College of Data Science, Taiyuan University of...   \n",
       "1  School of Information Science and Engineering,...   \n",
       "\n",
       "                 Publication Title Date Added To Xplore  Publication Year  \\\n",
       "0  Tsinghua Science and Technology            21-Jul-22              2023   \n",
       "1  Tsinghua Science and Technology            21-Jul-22              2023   \n",
       "\n",
       "  Volume  Issue Start Page  ... Mesh_Terms Article Citation Count  \\\n",
       "0     28    1.0        117  ...        NaN                    NaN   \n",
       "1     28    1.0        176  ...        NaN                    NaN   \n",
       "\n",
       "  Patent Citation Count Reference Count License Online Date Issue Date  \\\n",
       "0                   NaN            49.0     NaN   21-Jul-22        NaN   \n",
       "1                   NaN             NaN     NaN   21-Jul-22        NaN   \n",
       "\n",
       "  Meeting Date Publisher Document Identifier  \n",
       "0          NaN       TUP        TUP Journals  \n",
       "1          NaN       TUP        TUP Journals  \n",
       "\n",
       "[2 rows x 31 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Total number of rows and columns:  (1558, 31)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Sno', 'Document Title', 'Authors', 'Author Affiliations',\n",
       "       'Publication Title', 'Date Added To Xplore', 'Publication Year',\n",
       "       'Volume', 'Issue', 'Start Page', 'End Page', 'Abstract', 'ISSN',\n",
       "       'ISBNs', 'DOI', 'Funding Information', 'PDF Link', 'Author Keywords',\n",
       "       'IEEE Terms', 'INSPEC Controlled Terms', 'INSPEC Non-Controlled Terms',\n",
       "       'Mesh_Terms', 'Article Citation Count', 'Patent Citation Count',\n",
       "       'Reference Count', 'License', 'Online Date', 'Issue Date',\n",
       "       'Meeting Date', 'Publisher', 'Document Identifier'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\" Total number of rows and columns: \", articles.shape) \n",
    "articles.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are unnecessary columns for our recommender system so removing  these in the first phase and arranging their order also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sno, Document Title, Authors, Publication Year, Abstract, DOI, PDF Link, Author Keywords, Online Date, Document Identifier\n",
    "articles = articles[['Document Title', 'Abstract', 'Authors', 'Author Keywords',\\\n",
    "     'IEEE Terms','Publication Year', 'Document Identifier', 'DOI', 'PDF Link']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1558, 9)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# renaming the colums to standard formate \n",
    "articles = articles.rename(columns={'Document Title': 'title',\\\n",
    "    'Abstract': 'abstract', 'Authors': 'authors', 'Author Keywords': 'Keywords',\\\n",
    "        'IEEE Terms': 'ieeeKeywords', 'Publication Year': 'year',\\\n",
    "            'Document Identifier': 'journal','DOI': 'doi', 'PDF Link': 'pdfLink' })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title', 'abstract', 'authors', 'Keywords', 'ieeeKeywords', 'year',\n",
       "       'journal', 'doi', 'pdfLink'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1547"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total is 1558 articles which have some duplicated \n",
    "len(articles['title'].unique()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1538"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(articles['abstract'].unique()) # to chect the duplicated or unique items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1558"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# article link is unique , didnot contain duplicated links\n",
    "len(articles['pdfLink'].unique()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1558 entries, 0 to 1557\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   title         1558 non-null   object\n",
      " 1   abstract      1540 non-null   object\n",
      " 2   authors       1526 non-null   object\n",
      " 3   Keywords      1484 non-null   object\n",
      " 4   ieeeKeywords  1514 non-null   object\n",
      " 5   year          1558 non-null   int64 \n",
      " 6   journal       1558 non-null   object\n",
      " 7   doi           1548 non-null   object\n",
      " 8   pdfLink       1558 non-null   object\n",
      "dtypes: int64(1), object(8)\n",
      "memory usage: 109.7+ KB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "articles.info() # to check the null values which ha\n",
    "# abstract = 10, author = 26 ,etc , "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# duplicat =aritcles[aritcles.duplicated('title')]  to show the duplicated row\n",
    "articles.duplicated('title').sum() # total duplicated rows count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop nul and emply values from title and abstract colums and others columns will fill by some values\n",
    "articles = articles.dropna(subset=['abstract', 'doi'], how= 'any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title            0\n",
       "abstract         0\n",
       "authors         18\n",
       "Keywords        53\n",
       "ieeeKeywords    28\n",
       "year             0\n",
       "journal          0\n",
       "doi              0\n",
       "pdfLink          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(articles.isnull() | articles.empty).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the nul values from authors column \n",
    "articles = articles.dropna(subset='authors') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title            0\n",
       "abstract         0\n",
       "authors          0\n",
       "Keywords        35\n",
       "ieeeKeywords    10\n",
       "year             0\n",
       "journal          0\n",
       "doi              0\n",
       "pdfLink          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the author keywords and ieee keywords are mostly similar\n",
    "# so  remove null values when the both colums are empty\n",
    "(articles.isnull() | articles.empty).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to check autor keyword and ieee keyword on AND condition  where both columns are nul values\n",
    "(articles['Keywords'].isnull() & articles['ieeeKeywords'].isnull()).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to drop the null values from the both columns when both have null values \n",
    "articles = articles.dropna(subset=['Keywords', 'ieeeKeywords'], how=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title            0\n",
       "abstract         0\n",
       "authors          0\n",
       "Keywords        29\n",
       "ieeeKeywords     4\n",
       "year             0\n",
       "journal          0\n",
       "doi              0\n",
       "pdfLink          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(articles.isnull() | articles.empty).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles.duplicated('title').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles.duplicated('abstract').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles.duplicated('doi').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles.duplicated('pdfLink').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill the missing values of author keywords from the corresponding values of\n",
    "#  ieee keyword because both columns have mostly similar keywordss \n",
    "articles['Keywords'].fillna(articles['ieeeKeywords'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1506, 9)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title           0\n",
       "abstract        0\n",
       "authors         0\n",
       "Keywords        0\n",
       "ieeeKeywords    4\n",
       "year            0\n",
       "journal         0\n",
       "doi             0\n",
       "pdfLink         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no need to fill the missing values in ieeeKeywords , now it's unnecessary we will drop it soon\n",
    "(articles.isnull() | articles.empty).sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping ieeeKewword , we added this because to fill up the author keyword, now its unneccessory \n",
    "articles.drop(\"ieeeKeywords\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ISO 639-1 code , you can search in google , this is list of languages supported by python\n",
    "from langdetect import detect # detect_langs is used to show the % of text\n",
    "languages = articles['abstract'].apply(detect) # .unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='abstract', ylabel='count'>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# all articles writen in English language \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import seaborn as sns\n",
    "languages\n",
    "languages.value_counts(normalize=True)*100\n",
    "sns.countplot(languages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we have to extract text link from correspondents values of pdf Link columns, there is a little difference between text link and pdf link ie    \n",
    " PDF link:  https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9836995                                             \n",
    " text link: https://ieeexplore.ieee.org/document/9836995                                                   so we have create duplicate colum from pdfLink and rename it textLink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creat textLink from pdfLink.from pdflink to text\n",
    "articles['textLink'] = articles.loc[:, 'pdfLink']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now change the all links in text link column to specific\n",
    "#  format, from pdf links to text links , we just copied before\n",
    "#  PDF link:  https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9836995                                             \n",
    "#  text link: https://ieeexplore.ieee.org/document/9836995\n",
    "\n",
    "import re\n",
    "def convertLink(link):\n",
    "    x = link.replace(\"stamp/stamp.jsp?arnumber=\", \"document/\")\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles['textLink'] = articles['textLink'].apply(convertLink)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1506 entries, 0 to 1547\n",
      "Data columns (total 9 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   title     1506 non-null   object\n",
      " 1   abstract  1506 non-null   object\n",
      " 2   authors   1506 non-null   object\n",
      " 3   Keywords  1506 non-null   object\n",
      " 4   year      1506 non-null   int64 \n",
      " 5   journal   1506 non-null   object\n",
      " 6   doi       1506 non-null   object\n",
      " 7   pdfLink   1506 non-null   object\n",
      " 8   textLink  1506 non-null   object\n",
      "dtypes: int64(1), object(8)\n",
      "memory usage: 117.7+ KB\n"
     ]
    }
   ],
   "source": [
    "articles.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creat new dataframe from the articles dataframe for vectorization and building model\n",
    "soup = articles[['title', 'Keywords']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1506, 2)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer # lemitize words to meaningful for\n",
    "lm = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creat a function to clean the text\n",
    "def removeSigns(txt):\n",
    "    cleanText = []\n",
    "    txt = re.sub(r'[^\\w\\s]', '', txt) # remove all puntuation marks\n",
    "    txt = re.sub(\"[0-9]\", '', txt) # remove digits\n",
    "    txt = re.sub('(\\\\b[A-Za-z] \\\\b|\\\\b [A-Za-z]\\\\b)', '', txt) #remove single charater or digits\n",
    "    txt = re.sub(\"\\s+\", \" \", txt) # remove multipl spaces to single\n",
    "    txt = txt.strip() # remove leading and tailing spaces\n",
    "    txt = txt.lower()\n",
    "    txt = txt.split() \n",
    "    txt = [lm.lemmatize(word) for word in txt if not word in stopwords.words('english')]\n",
    "    txt = ' '.join(txt) \n",
    "    \n",
    "    cleanText.append(txt)\n",
    "    return cleanText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    KTI-RNN: Recognition of Heart Failure from Cli...\n",
       "1    Blockchain Data Analysis from the Perspective ...\n",
       "2    Co-Concurrency Mechanism for Multi-GPUs in Dis...\n",
       "3    Deep Learning based Cross Domain Sentiment Cla...\n",
       "4    A Comprehensive Review of Deep Learning-based ...\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup['title'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup['title'] = soup['title'].apply(removeSigns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [ktirnn recognition heart failure clinical note]\n",
       "1    [blockchain data analysis perspective complex ...\n",
       "2    [coconcurrency mechanism multigpus distributed...\n",
       "3    [deep learning based cross domain sentiment cl...\n",
       "4    [comprehensive review deep learningbased metho...\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup['title'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    heart failure;diagnosis;text classification;de...\n",
       "1    blockchain;cryptocurrency;transaction record;c...\n",
       "2    concurrent kernel execution;heterogeneous comp...\n",
       "3    Cross-domain sentiment analysis;deep learning;...\n",
       "4    Machine Learning;Pneumonia;Radiology;Diagnosti...\n",
       "Name: Keywords, dtype: object"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup['Keywords'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanKeys(txt):\n",
    "    cleanText = []\n",
    "    txt = re.sub('\\.|\\:|\\-|\\,', '', txt) # remove . : and - merged words with no space\n",
    "    # txt = re.sub('\\ ', '', txt) # remove white space\n",
    "    txt = re.sub('\\;', ' ', txt) # add space afer the ; sign\n",
    "    txt = re.sub(\"\\(|\\[|\\{\", \" \", txt)\n",
    "    txt = re.sub(\"\\)|\\]|\\}\", \"\", txt)\n",
    "    txt = txt.lower()\n",
    "    txt = txt.split()\n",
    "    txt = [lm.lemmatize(word) for word in txt if not word in stopwords.words('english')]\n",
    "    txt = ' '.join(txt)\n",
    "    cleanText.append(txt)\n",
    "    return cleanText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup['Keywords'] = soup['Keywords'].apply(cleanKeys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [heart failure diagnosis text classification d...\n",
       "1    [blockchain cryptocurrency transaction record ...\n",
       "2    [concurrent kernel execution heterogeneous com...\n",
       "3    [crossdomain sentiment analysis deep learning ...\n",
       "4    [machine learning pneumonia radiology diagnost...\n",
       "Name: Keywords, dtype: object"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup['Keywords'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>Keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[ktirnn recognition heart failure clinical note]</td>\n",
       "      <td>[heart failure diagnosis text classification d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[blockchain data analysis perspective complex ...</td>\n",
       "      <td>[blockchain cryptocurrency transaction record ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[coconcurrency mechanism multigpus distributed...</td>\n",
       "      <td>[concurrent kernel execution heterogeneous com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[deep learning based cross domain sentiment cl...</td>\n",
       "      <td>[crossdomain sentiment analysis deep learning ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[comprehensive review deep learningbased metho...</td>\n",
       "      <td>[machine learning pneumonia radiology diagnost...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0   [ktirnn recognition heart failure clinical note]   \n",
       "1  [blockchain data analysis perspective complex ...   \n",
       "2  [coconcurrency mechanism multigpus distributed...   \n",
       "3  [deep learning based cross domain sentiment cl...   \n",
       "4  [comprehensive review deep learningbased metho...   \n",
       "\n",
       "                                            Keywords  \n",
       "0  [heart failure diagnosis text classification d...  \n",
       "1  [blockchain cryptocurrency transaction record ...  \n",
       "2  [concurrent kernel execution heterogeneous com...  \n",
       "3  [crossdomain sentiment analysis deep learning ...  \n",
       "4  [machine learning pneumonia radiology diagnost...  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert list to strings to concatenate the colums\n",
    "soup['title']= soup['title'].apply(lambda x: \" \".join(x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup['Keywords']= soup['Keywords'].apply(lambda x: \" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the title column and kewword coloum named it tags\n",
    "soup['tags'] = soup['title']+' , '+ soup['Keywords'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'deep learning based cross domain sentiment classification urdu language , crossdomain sentiment analysis deep learning urdu language processing feature engineering'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup['tags'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup['tags']= soup['tags'].apply(lambda x: x.replace(',', '')) #to remove the comma from the tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'deep learning based cross domain sentiment classification urdu language  crossdomain sentiment analysis deep learning urdu language processing feature engineering'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup['tags'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup['tags'] = soup['tags'].apply(lambda x: x.replace('  ', ' ')) # remove duble space to singl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ktirnn recognition heart failure clinical note</td>\n",
       "      <td>heart failure diagnosis text classification de...</td>\n",
       "      <td>ktirnn recognition heart failure clinical note...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blockchain data analysis perspective complex n...</td>\n",
       "      <td>blockchain cryptocurrency transaction record c...</td>\n",
       "      <td>blockchain data analysis perspective complex n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>coconcurrency mechanism multigpus distributed ...</td>\n",
       "      <td>concurrent kernel execution heterogeneous comp...</td>\n",
       "      <td>coconcurrency mechanism multigpus distributed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>deep learning based cross domain sentiment cla...</td>\n",
       "      <td>crossdomain sentiment analysis deep learning u...</td>\n",
       "      <td>deep learning based cross domain sentiment cla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>comprehensive review deep learningbased method...</td>\n",
       "      <td>machine learning pneumonia radiology diagnosti...</td>\n",
       "      <td>comprehensive review deep learningbased method...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0     ktirnn recognition heart failure clinical note   \n",
       "1  blockchain data analysis perspective complex n...   \n",
       "2  coconcurrency mechanism multigpus distributed ...   \n",
       "3  deep learning based cross domain sentiment cla...   \n",
       "4  comprehensive review deep learningbased method...   \n",
       "\n",
       "                                            Keywords  \\\n",
       "0  heart failure diagnosis text classification de...   \n",
       "1  blockchain cryptocurrency transaction record c...   \n",
       "2  concurrent kernel execution heterogeneous comp...   \n",
       "3  crossdomain sentiment analysis deep learning u...   \n",
       "4  machine learning pneumonia radiology diagnosti...   \n",
       "\n",
       "                                                tags  \n",
       "0  ktirnn recognition heart failure clinical note...  \n",
       "1  blockchain data analysis perspective complex n...  \n",
       "2  coconcurrency mechanism multigpus distributed ...  \n",
       "3  deep learning based cross domain sentiment cla...  \n",
       "4  comprehensive review deep learningbased method...  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer # import the feature extraction model n-gram\n",
    "ngramVC = CountVectorizer(ngram_range=(1, 1), max_features=400,)\n",
    "ngramX = ngramVC.fit_transform(soup['tags']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1506, 400)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngramX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creat dataframe from the vectors\n",
    "df = pd.DataFrame(ngramX, columns= ngramVC.get_feature_names())\n",
    "# ngramVC.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3d</th>\n",
       "      <th>action</th>\n",
       "      <th>active</th>\n",
       "      <th>activity</th>\n",
       "      <th>adaptation</th>\n",
       "      <th>adaptive</th>\n",
       "      <th>adversarial</th>\n",
       "      <th>aggregation</th>\n",
       "      <th>agriculture</th>\n",
       "      <th>ai</th>\n",
       "      <th>...</th>\n",
       "      <th>view</th>\n",
       "      <th>virtual</th>\n",
       "      <th>vision</th>\n",
       "      <th>visual</th>\n",
       "      <th>visualization</th>\n",
       "      <th>vulnerability</th>\n",
       "      <th>web</th>\n",
       "      <th>wireless</th>\n",
       "      <th>word</th>\n",
       "      <th>zeroshot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 400 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   3d  action  active  activity  adaptation  adaptive  adversarial  \\\n",
       "0   0       0       0         0           0         0            0   \n",
       "1   0       0       0         0           0         0            0   \n",
       "2   0       0       0         0           0         0            0   \n",
       "3   0       0       0         0           0         0            0   \n",
       "4   0       0       0         0           0         0            0   \n",
       "\n",
       "   aggregation  agriculture  ai  ...  view  virtual  vision  visual  \\\n",
       "0            0            0   0  ...     0        0       0       0   \n",
       "1            0            0   0  ...     0        0       0       0   \n",
       "2            0            0   0  ...     0        0       0       0   \n",
       "3            0            0   0  ...     0        0       0       0   \n",
       "4            0            0   0  ...     0        0       0       0   \n",
       "\n",
       "   visualization  vulnerability  web  wireless  word  zeroshot  \n",
       "0              0              0    0         0     0         0  \n",
       "1              0              0    0         0     0         0  \n",
       "2              0              0    0         0     0         0  \n",
       "3              0              0    0         0     0         0  \n",
       "4              0              0    0         0     0         0  \n",
       "\n",
       "[5 rows x 400 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= df.set_index(articles['title']) # set index as 'title' from the articles dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3d</th>\n",
       "      <th>action</th>\n",
       "      <th>active</th>\n",
       "      <th>activity</th>\n",
       "      <th>adaptation</th>\n",
       "      <th>adaptive</th>\n",
       "      <th>adversarial</th>\n",
       "      <th>aggregation</th>\n",
       "      <th>agriculture</th>\n",
       "      <th>ai</th>\n",
       "      <th>...</th>\n",
       "      <th>view</th>\n",
       "      <th>virtual</th>\n",
       "      <th>vision</th>\n",
       "      <th>visual</th>\n",
       "      <th>visualization</th>\n",
       "      <th>vulnerability</th>\n",
       "      <th>web</th>\n",
       "      <th>wireless</th>\n",
       "      <th>word</th>\n",
       "      <th>zeroshot</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KTI-RNN: Recognition of Heart Failure from Clinical Notes</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blockchain Data Analysis from the Perspective of Complex Networks: Overview</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 400 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    3d  action  active  \\\n",
       "title                                                                    \n",
       "KTI-RNN: Recognition of Heart Failure from Clin...   0       0       0   \n",
       "Blockchain Data Analysis from the Perspective o...   0       0       0   \n",
       "\n",
       "                                                    activity  adaptation  \\\n",
       "title                                                                      \n",
       "KTI-RNN: Recognition of Heart Failure from Clin...         0           0   \n",
       "Blockchain Data Analysis from the Perspective o...         0           0   \n",
       "\n",
       "                                                    adaptive  adversarial  \\\n",
       "title                                                                       \n",
       "KTI-RNN: Recognition of Heart Failure from Clin...         0            0   \n",
       "Blockchain Data Analysis from the Perspective o...         0            0   \n",
       "\n",
       "                                                    aggregation  agriculture  \\\n",
       "title                                                                          \n",
       "KTI-RNN: Recognition of Heart Failure from Clin...            0            0   \n",
       "Blockchain Data Analysis from the Perspective o...            0            0   \n",
       "\n",
       "                                                    ai  ...  view  virtual  \\\n",
       "title                                                   ...                  \n",
       "KTI-RNN: Recognition of Heart Failure from Clin...   0  ...     0        0   \n",
       "Blockchain Data Analysis from the Perspective o...   0  ...     0        0   \n",
       "\n",
       "                                                    vision  visual  \\\n",
       "title                                                                \n",
       "KTI-RNN: Recognition of Heart Failure from Clin...       0       0   \n",
       "Blockchain Data Analysis from the Perspective o...       0       0   \n",
       "\n",
       "                                                    visualization  \\\n",
       "title                                                               \n",
       "KTI-RNN: Recognition of Heart Failure from Clin...              0   \n",
       "Blockchain Data Analysis from the Perspective o...              0   \n",
       "\n",
       "                                                    vulnerability  web  \\\n",
       "title                                                                    \n",
       "KTI-RNN: Recognition of Heart Failure from Clin...              0    0   \n",
       "Blockchain Data Analysis from the Perspective o...              0    0   \n",
       "\n",
       "                                                    wireless  word  zeroshot  \n",
       "title                                                                         \n",
       "KTI-RNN: Recognition of Heart Failure from Clin...         0     0         0  \n",
       "Blockchain Data Analysis from the Perspective o...         0     0         0  \n",
       "\n",
       "[2 rows x 400 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ..., False, False, False])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.index=='coconcurrency mechanism multigpus distributed heterogeneous environment'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors # unsuporvised learning algroithm \n",
    "nn = NearestNeighbors(algorithm = 'brute') # algorithm = 'brute'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recomend(paper):\n",
    "    id = np.where(df.index == paper)[0][0]\n",
    "    distances, suggestions = (model.kneighbors(df.iloc[id,:].values.reshape(1, -1), n_neighbors=6))\n",
    "    paperList = []\n",
    "    for i in suggestions:\n",
    "        paperList.append(articles.iloc[i])\n",
    "    return paperList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[                                                  title  \\\n",
       " 3     Deep Learning based Cross Domain Sentiment Cla...   \n",
       " 251   A Deep Learning Approach for Public Sentiment ...   \n",
       " 1130  Deep Learning Techniques for Aspect Based Sent...   \n",
       " 69    Multi-ideology Multi-class Extremism Classific...   \n",
       " 951   Sarcasm Over Time and Across Platforms: Does t...   \n",
       " 87    Aspect-Opinion Correlation Aware and Knowledge...   \n",
       " \n",
       "                                                abstract  \\\n",
       " 3     Sentiment analysis is a widely researched area...   \n",
       " 251   Sentiment analysis is a process of extracting ...   \n",
       " 1130  Sentiment analysis is an important tool, which...   \n",
       " 69    Social media is an integral part of today’s so...   \n",
       " 951   Sarcasm is a sophisticated form of speech used...   \n",
       " 87    Cross-domain sentiment analysis has recently a...   \n",
       " \n",
       "                                                 authors  \\\n",
       " 3     A. Altaf; M. W. Anwar; M. Hasan Jamal; S. Hass...   \n",
       " 251   G. M. S. Hossain; S. Asaduzzaman; M. Mynoddin;...   \n",
       " 1130                                    S. Chen; G. Fnu   \n",
       " 69       M. Gaikwad; S. Ahirrao; K. Kotecha; A. Abraham   \n",
       " 951                             M. Bouazizi; T. Ohtsuki   \n",
       " 87         H. Ren; Y. Cai; Y. Zeng; J. Ye; H. -f. Leung   \n",
       " \n",
       "                                                Keywords  year  \\\n",
       " 3     Cross-domain sentiment analysis;deep learning;...  2022   \n",
       " 251     Sentiment Analysis;Deep Learning;BiGRU;Word2Vec  2022   \n",
       " 1130    sentiment analysis;deep learning;neural network  2022   \n",
       " 69    extremism;hate;propaganda;radicalization;recru...  2022   \n",
       " 951   Deep learning;machine learning;sarcasm detecti...  2022   \n",
       " 87    Cross domain sentiment analysis;few-shot learn...  2022   \n",
       " \n",
       "                          journal                              doi  \\\n",
       " 3     IEEE Early Access Articles      10.1109/ACCESS.2022.3208164   \n",
       " 251             IEEE Conferences  10.1109/CONIT55038.2022.9847839   \n",
       " 1130            IEEE Conferences  10.1109/ICCRD54409.2022.9730443   \n",
       " 69    IEEE Early Access Articles      10.1109/ACCESS.2022.3205744   \n",
       " 951                IEEE Journals      10.1109/ACCESS.2022.3174862   \n",
       " 87    IEEE Early Access Articles       10.1109/TAFFC.2022.3205358   \n",
       " \n",
       "                                                 pdfLink  \\\n",
       " 3     https://ieeexplore.ieee.org/stamp/stamp.jsp?ar...   \n",
       " 251   https://ieeexplore.ieee.org/stamp/stamp.jsp?ar...   \n",
       " 1130  https://ieeexplore.ieee.org/stamp/stamp.jsp?ar...   \n",
       " 69    https://ieeexplore.ieee.org/stamp/stamp.jsp?ar...   \n",
       " 951   https://ieeexplore.ieee.org/stamp/stamp.jsp?ar...   \n",
       " 87    https://ieeexplore.ieee.org/stamp/stamp.jsp?ar...   \n",
       " \n",
       "                                           textLink  \n",
       " 3     https://ieeexplore.ieee.org/document/9895382  \n",
       " 251   https://ieeexplore.ieee.org/document/9847839  \n",
       " 1130  https://ieeexplore.ieee.org/document/9730443  \n",
       " 69    https://ieeexplore.ieee.org/document/9885202  \n",
       " 951   https://ieeexplore.ieee.org/document/9774408  \n",
       " 87    https://ieeexplore.ieee.org/document/9882094  ]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recomend('Deep Learning based Cross Domain Sentiment Classification for Urdu Language')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # importing jobib file of Articles , df and model\n",
    "# from joblib import dump\n",
    "# fileName = 'data.joblib'\n",
    "# dump(articles, fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump(df, 'vectors.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump(model, 'nnModel.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
